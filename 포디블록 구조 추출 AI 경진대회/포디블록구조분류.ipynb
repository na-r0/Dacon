{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 포디블록 구조 추출 AI 경진대회\n",
    "---\n",
    "출처: https://dacon.io/competitions/official/236046/overview/description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import random\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from os.path import exists\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0, EfficientNetB3, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img_path</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>J</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_00000</td>\n",
       "      <td>./train/TRAIN_00000.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_00001</td>\n",
       "      <td>./train/TRAIN_00001.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_00002</td>\n",
       "      <td>./train/TRAIN_00002.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_00003</td>\n",
       "      <td>./train/TRAIN_00003.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_00004</td>\n",
       "      <td>./train/TRAIN_00004.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                 img_path  A  B  C  D  E  F  G  H  I  J\n",
       "0  TRAIN_00000  ./train/TRAIN_00000.jpg  1  0  0  0  0  0  0  0  0  0\n",
       "1  TRAIN_00001  ./train/TRAIN_00001.jpg  1  0  0  0  0  0  0  0  0  0\n",
       "2  TRAIN_00002  ./train/TRAIN_00002.jpg  1  0  0  0  0  0  0  0  0  0\n",
       "3  TRAIN_00003  ./train/TRAIN_00003.jpg  1  0  0  0  0  0  0  0  0  0\n",
       "4  TRAIN_00004  ./train/TRAIN_00004.jpg  1  0  0  0  0  0  0  0  0  0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 학습/검증 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)\n",
    "train_len = int(len(df) * 0.8)\n",
    "\n",
    "train = df[:train_len].reset_index(drop=True)\n",
    "val = df[train_len:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = train['img_path']\n",
    "path_valid = val['img_path']\n",
    "path_test = test['img_path']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. TFRecord 생성\n",
    "\n",
    "---\n",
    "TFRecord 안은 Protocol Buffer이라는 바이너리 포맷으로 되어 있다. 한 번 TFRecord를 작성하는 것으로 데이터의 생성, 가공 비용을 줄일 수 있는 경우가 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26395it [02:53, 152.53it/s]\n"
     ]
    }
   ],
   "source": [
    "## TFRecord writer 생성\n",
    "writer_image = tf.io.TFRecordWriter('image_train.tfr')\n",
    "for i_, path_ in tqdm(enumerate(path_train)):\n",
    "\n",
    "    src = cv2.imread(path_)\n",
    "    dst = cv2.cvtColor(src, cv2.COLOR_BGR2RGB)\n",
    "    dst = cv2.resize(dst, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_CUBIC)\n",
    "    bimage = dst.tobytes()\n",
    "    \n",
    "    classes = np.array(train.loc[i_, 'A':'J'], dtype=np.uint8).tobytes()\n",
    "    \n",
    "    example = tf.train.Example(\n",
    "        features=tf.train.Features(\n",
    "            feature={\n",
    "                'image': _bytes_feature(bimage),\n",
    "                'classes': _bytes_feature(classes)\n",
    "            }\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    writer_image.write(example.SerializeToString())\n",
    "    \n",
    "writer_image.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6599it [00:44, 149.01it/s]\n"
     ]
    }
   ],
   "source": [
    "writer_image_valid = tf.io.TFRecordWriter('image_valid.tfr')\n",
    "for i_, path_ in tqdm(enumerate(path_valid)):\n",
    "\n",
    "    src = cv2.imread(path_)\n",
    "    dst = cv2.cvtColor(src, cv2.COLOR_BGR2RGB)\n",
    "    dst = cv2.resize(dst, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_CUBIC)    \n",
    "    bimage = dst.tobytes()\n",
    "    \n",
    "    classes = np.array(val.loc[i_, 'A':'J'], dtype=np.uint8).tobytes()\n",
    "    \n",
    "    example = tf.train.Example(\n",
    "        features=tf.train.Features(\n",
    "            feature={\n",
    "                'image': _bytes_feature(bimage),\n",
    "                'classes': _bytes_feature(classes)            \n",
    "            }\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    writer_image_valid.write(example.SerializeToString())\n",
    "    \n",
    "writer_image_valid.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1460it [00:10, 134.40it/s]\n"
     ]
    }
   ],
   "source": [
    "writer_image_test = tf.io.TFRecordWriter('image_test.tfr')\n",
    "\n",
    "for i_, path_ in tqdm(enumerate(path_test)):\n",
    "\n",
    "    src = cv2.imread(path_)\n",
    "    dst = cv2.cvtColor(src, cv2.COLOR_BGR2RGB)\n",
    "    dst = cv2.resize(dst, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    bimage = dst.tobytes()\n",
    "    \n",
    "    example = tf.train.Example(\n",
    "        features=tf.train.Features(\n",
    "            feature={\n",
    "                'image': _bytes_feature(bimage)\n",
    "            }\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    writer_image_test.write(example.SerializeToString())\n",
    "    \n",
    "writer_image_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tfrecord file을 data로 parsing해주는 function\n",
    "def _parse_function(tfrecord_serialized):\n",
    "    features={'image': tf.io.FixedLenFeature([], tf.string),\n",
    "              'classes': tf.io.FixedLenFeature([], tf.string)\n",
    "             }\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord_serialized, features)\n",
    "    \n",
    "    image = tf.io.decode_raw(parsed_features['image'], tf.uint8)\n",
    "    image = tf.reshape(image, [IMG_SIZE, IMG_SIZE, 3])\n",
    "#     image = tf.cast(image, tf.float32)/255. \n",
    "\n",
    "    classes = tf.io.decode_raw(parsed_features['classes'], tf.uint8)    \n",
    "    classes = tf.squeeze(classes)\n",
    "\n",
    "    return image, classes\n",
    "\n",
    "def _parse_function2(tfrecord_serialized):\n",
    "    features={'image': tf.io.FixedLenFeature([], tf.string)             }\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord_serialized, features)\n",
    "    \n",
    "    image = tf.io.decode_raw(parsed_features['image'], tf.uint8)\n",
    "    image = tf.reshape(image, [IMG_SIZE, IMG_SIZE, 3])\n",
    "#     image = tf.cast(image, tf.float32)/255. \n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train dataset 만들기\n",
    "train_dataset = tf.data.TFRecordDataset('image_train.tfr')\n",
    "train_dataset = train_dataset.map(_parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_dataset = train_dataset.shuffle(2000).prefetch(tf.data.experimental.AUTOTUNE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## validation dataset 만들기\n",
    "val_dataset = tf.data.TFRecordDataset('image_valid.tfr')\n",
    "val_dataset = val_dataset.map(_parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "val_dataset = val_dataset.prefetch(tf.data.experimental.AUTOTUNE).batch(BATCH_SIZE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
